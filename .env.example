# Copy this file to `.env` or `.env.local` and fill in secrets.
# Do NOT commit your `.env` (it is gitignored). `.env.example` is safe to commit.

# -----------------------------------------------------------------------------
# Core runtime (required for CLI)
# -----------------------------------------------------------------------------

APP_ENV=local
APP_TIMEZONE=UTC

# Matches docker-compose.yml defaults (Postgres + Redis)
DATABASE_URL=postgres://aharadar:aharadar_dev_password@localhost:5432/aharadar
REDIS_URL=redis://localhost:6379

# Budgets (required)
MONTHLY_CREDITS=10000
DEFAULT_TIER=normal

# Budgets (optional)
DAILY_THROTTLE_CREDITS=

# Optional auth (used by API/admin surfaces when enabled)
ADMIN_API_KEY=dev-api-key

# API server port (default: 3001)
API_PORT=3001

# -----------------------------------------------------------------------------
# User API Key Encryption
# -----------------------------------------------------------------------------

# Encryption key for user API keys (32 bytes, hex encoded)
# Generate with: openssl rand -hex 32
APP_ENCRYPTION_KEY=

# Allow fallback to system API keys when user has none configured
ALLOW_SYSTEM_KEY_FALLBACK=true

# -----------------------------------------------------------------------------
# LLM (OpenAI-compatible Responses API) — used for triage today
# -----------------------------------------------------------------------------

OPENAI_API_KEY=

# Prefer base URL; code appends `/v1/responses` for LLM calls (and `/v1/embeddings` for embeddings).
OPENAI_BASE_URL=https://api.openai.com

# Optional explicit endpoint override (full URL to `/v1/responses`)
OPENAI_ENDPOINT=

# Model selection
OPENAI_MODEL=
OPENAI_TRIAGE_MODEL=
OPENAI_TRIAGE_MODEL_LOW=
OPENAI_TRIAGE_MODEL_NORMAL=
OPENAI_TRIAGE_MODEL_HIGH=

# Triage controls (optional)
OPENAI_TRIAGE_MAX_OUTPUT_TOKENS=250
OPENAI_TRIAGE_MAX_INPUT_CHARS=4000
OPENAI_TRIAGE_MAX_TITLE_CHARS=240
OPENAI_TRIAGE_MAX_CALLS_PER_RUN=
OPENAI_TRIAGE_REASONING_EFFORT=

# Credits estimate (optional)
OPENAI_CREDITS_PER_1K_INPUT_TOKENS=
OPENAI_CREDITS_PER_1K_OUTPUT_TOKENS=
OPENAI_TRIAGE_CREDITS_PER_1K_INPUT_TOKENS=
OPENAI_TRIAGE_CREDITS_PER_1K_OUTPUT_TOKENS=

# -----------------------------------------------------------------------------
# Embeddings (OpenAI-compatible) — used for embed stage + semantic search
# -----------------------------------------------------------------------------

OPENAI_EMBED_MODEL=
OPENAI_EMBED_MODEL_LOW=
OPENAI_EMBED_MODEL_NORMAL=
OPENAI_EMBED_MODEL_HIGH=

# Optional explicit endpoint override (full URL to `/v1/embeddings`).
# If omitted and OPENAI_BASE_URL is set, it is derived automatically.
OPENAI_EMBED_ENDPOINT=

# Embed stage controls (optional)
OPENAI_EMBED_MAX_ITEMS_PER_RUN=100
OPENAI_EMBED_BATCH_SIZE=16
OPENAI_EMBED_MAX_INPUT_CHARS=8000

# Credits estimate (optional)
OPENAI_EMBED_CREDITS_PER_1K_INPUT_TOKENS=
# Legacy alias (accepted by code)
OPENAI_EMBED_CREDITS_PER_1K_TOKENS=

# -----------------------------------------------------------------------------
# Signal connector (X/Twitter search via Grok) — optional
# -----------------------------------------------------------------------------

# Required for signal sources to fetch
SIGNAL_GROK_API_KEY=
# Alternate name supported by code
GROK_API_KEY=

# Preferred: base URL (code appends `/v1/responses`)
SIGNAL_GROK_BASE_URL=
# Alternate name supported by code
GROK_BASE_URL=

# Optional explicit endpoint override (full URL to `/v1/responses`)
SIGNAL_GROK_ENDPOINT=

# Optional tuning
SIGNAL_GROK_MODEL=
SIGNAL_GROK_MAX_OUTPUT_TOKENS=
SIGNAL_GROK_ENABLE_X_SEARCH_TOOL=1

# Budget/caps (optional)
SIGNAL_MAX_SEARCH_CALLS_PER_RUN=
SIGNAL_CREDITS_PER_CALL=
